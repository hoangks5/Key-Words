{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r',encoding='utf-8') as file:\n",
    "    full_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyphrase:  octet-stream type posts : score 0.012957445239480963\n",
      "Keyphrase:  form-data type forms : score 0.016356499078172874\n",
      "Keyphrase:  octet-stream type : score 0.028378849701799807\n",
      "Keyphrase:  form-data type : score 0.028378849701799807\n",
      "Keyphrase:  working using application : score 0.028785995937607795\n",
      "Keyphrase:  images using flask : score 0.028785995937607795\n",
      "Keyphrase:  upload images : score 0.06424318756146702\n",
      "Keyphrase:  request working : score 0.07076208983559576\n",
      "Keyphrase:  type posts : score 0.08189860827394943\n",
      "Keyphrase:  type : score 0.09377536030868192\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)\n",
    "keywords = kw_extractor.extract_keywords(full_text)\n",
    "for kw, v in keywords:\n",
    "  print(\"Keyphrase: \",kw, \": score\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('application/octet-stream type posts', 9.0), ('multipart/form-data type forms', 9.0), ('post based route', 7.0), ('request working', 4.0), ('upload images', 4.0), ('request element', 4.0), ('ajax call', 4.0), ('standard form', 3.5), ('post', 2.0), ('route', 2.0)]\n"
     ]
    }
   ],
   "source": [
    "from multi_rake import Rake\n",
    "rake = Rake()\n",
    "keywords = rake.apply(full_text)\n",
    "print(keywords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('worked leveraging', 0.53008566495395), ('request working', 0.5300856649539487), ('werkzeug', 0.2650428324769752)]\n"
     ]
    }
   ],
   "source": [
    "from summa import keywords\n",
    "TR_keywords = keywords.keywords(full_text, scores=True)\n",
    "print(TR_keywords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images using flask', 'support multiple upload', 'upload files', 'upload images using', 'multiple upload files', 'multiple upload', 'upload images', 'multipart form data', 'multipart form', 'using flask extended']\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "keywords = kw_model.extract_keywords(full_text, \n",
    "\n",
    "                                     keyphrase_ngram_range=(1, 3), \n",
    "\n",
    "                                     stop_words='english',\n",
    "\n",
    "                                     highlight=False,\n",
    "\n",
    "                                     top_n=10)\n",
    "\n",
    "keywords_list= list(dict(keywords).keys())\n",
    "print(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_gram_range = (1, 1)\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([full_text])\n",
    "candidates = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 690/690 [00:00<00:00, 206kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 68.7kB/s]\n",
      "Downloading: 100%|██████████| 3.99k/3.99k [00:00<00:00, 1.50MB/s]\n",
      "Downloading: 100%|██████████| 550/550 [00:00<00:00, 221kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 45.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([full_text])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
