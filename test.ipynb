{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r',encoding='utf-8') as file:\n",
    "    full_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyphrase:  Proof of Stake : score 0.0037218814086997045\n",
      "Keyphrase:  Internet Age : score 0.004807572690886256\n",
      "Keyphrase:  Proof of Work : score 0.005131495982340011\n",
      "Keyphrase:  Proof : score 0.008464898304442928\n",
      "Keyphrase:  blockchain : score 0.015710137894152452\n",
      "Keyphrase:  global trending headlines : score 0.016165480365113997\n",
      "Keyphrase:  timeline of Internet : score 0.016879318306396683\n",
      "Keyphrase:  Delegated Proof : score 0.01707220240951316\n",
      "Keyphrase:  Stake : score 0.020316235727219162\n",
      "Keyphrase:  validators : score 0.022194780558451727\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)\n",
    "keywords = kw_extractor.extract_keywords(full_text)\n",
    "for kw, v in keywords:\n",
    "  print(\"Keyphrase: \",kw, \": score\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('global trending headlines', 9.0), ('controversial talking point', 9.0), ('projects started rising', 9.0), ('promising effort-reward trade-off', 9.0), ('incremental holdings advocate', 9.0), ('strategic long-term vision', 9.0), ('oraichainâ€™s all-important decision', 8.666666666666666), ('digital cash system', 8.5), ('newly mined tokens', 8.428571428571429), ('owns governance tokens', 8.428571428571429)]\n"
     ]
    }
   ],
   "source": [
    "from multi_rake import Rake\n",
    "rake = Rake()\n",
    "keywords = rake.apply(full_text)\n",
    "print(keywords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('validators', 0.22505974620611613), ('validator', 0.22505974620611613), ('validate', 0.22505974620611613), ('network', 0.19432832205840733), ('networks', 0.19432832205840733), ('blockchain', 0.18265259880646112), ('blockchains', 0.18265259880646112), ('transactions', 0.1785068786788457), ('transaction', 0.1785068786788457), ('mechanisms', 0.16482030487051402)]\n"
     ]
    }
   ],
   "source": [
    "from summa import keywords\n",
    "TR_keywords = keywords.keywords(full_text, scores=True)\n",
    "print(TR_keywords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blockchain validators', 'validators blockchain networks', 'validators blockchain', 'distributed ledger', 'blockchain validators staked', 'blockchain validators fact', 'participating blockchain validators', 'blockchains', 'block distributed ledger', 'importance validators blockchain']\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "keywords = kw_model.extract_keywords(full_text, \n",
    "\n",
    "                                     keyphrase_ngram_range=(1, 3), \n",
    "\n",
    "                                     stop_words='english',\n",
    "\n",
    "                                     highlight=False,\n",
    "\n",
    "                                     top_n=10) \n",
    "\n",
    "keywords_list= list(dict(keywords).keys())\n",
    "print(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invasions global trending',\n",
       " 'navigating timeline internet',\n",
       " 'blockchain technology intensive',\n",
       " '1990s frequent invasions',\n",
       " 'frequent invasions global']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_gram_range = (1, 3)\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([full_text])\n",
    "candidates = count.get_feature_names()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([full_text])\n",
    "candidate_embeddings = model.encode(candidates)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "    return result\n",
    "output = set(get_hotwords(full_text))\n",
    "most_common_list = Counter(output).most_common(10)\n",
    "for item in most_common_list:\n",
    "  print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
