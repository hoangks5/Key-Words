
CHAPTER 4. NUMERICAL COMPUTATIONTo perform constrained maximization, we can construct the generalized La-grange function of −f (x), which leads to this optimization problem:minxmaxλmaxα,α≥0−f(x) +iλig(i)(x) +jαjh(j)(x). (4.19)We may also convert this to a problem with maximization in the outer loop:maxxminλminα,α≥0f(x) +iλig(i)(x) −jαjh(j)(x). (4.20)The sign of the term for the equality constraints does not matter; we may deﬁne itwith addition or subtraction as we wish, because the optimization is free to chooseany sign for each λi.The inequality constraints are particularly interesting. We say that a constrainth(i)(x) isactiveifh(i)(x∗) = 0. If a constraint is not active, then the solution tothe problem found using that constraint would remain at least a local solution ifthat constraint were removed. It is possible that an inactive constraint excludesother solutions. For example, a convex problem with an entire region of globallyoptimal points (a wide, ﬂat region of equal cost) could have a subset of thisregion eliminated by constraints, or a nonconvex problem could have better localstationary points excluded by a constraint that is inactive at convergence. Yet thepoint found at convergence remains a stationary point whether or not the inactiveconstraints are included. Because an inactiveh(i)has negative value, then thesolution tominxmaxλmaxα,α≥0L(x, λ, α) will haveαi= 0. We can thus observethat at the solution,α h(x) =0. In other words, for alli, we know that at leastone of the constraintsαi≥0 orh(i)(x)≤0 must be active at the solution. To gainsome intuition for this idea, we can say that either the solution is on the boundaryimposed by the inequality and we must use its KKT multiplier to inﬂuence thesolution tox, or the inequality has no inﬂuence on the solution and we representthis by zeroing out its KKT multiplier.A simple set of properties describe the optimal points of constrained opti-mization problems. These properties are called the Karush-Kuhn-Tucker (KKT)conditions (Karush, 1939; Kuhn and Tucker, 1951). They are necessary conditions,but not always suﬃcient conditions, for a point to be optimal. The conditions are:• The gradient of the generalized Lagrangian is zero.• All constraints on both x and the KKT multipliers are satisﬁed.•The inequality constraints exhibit “complementary slackness”:α h(x) =0.For more information about the KKT approach, see Nocedal and Wright (2006).93
CHAPTER 4. NUMERICAL COMPUTATION4.5 Example: Linear Least SquaresSuppose we want to ﬁnd the value of x that minimizesf(x) =12||Ax − b||22. (4.21)Specialized linear algebra algorithms can solve this problem eﬃciently; however,we can also explore how to solve it using gradient-based optimization as a simpleexample of how these techniques work.First, we need to obtain the gradient:∇xf(x) = A(Ax − b) = AAx − Ab. (4.22)We can then follow this gradient downhill, taking small steps. See algorithm 4.1for details.Algorithm 4.1An algorithm to minimizef(x) =12||Ax − b||22with respect toxusing gradient descent, starting from an arbitrary value of x.Set the step size () and tolerance (δ) to small, positive numbers.while ||AAx − Ab||2> δ dox ← x − AAx − Abend whileOne can also solve this problem using Newton’s method. In this case, becausethe true function is quadratic, the quadratic approximation employed by Newton’smethod is exact, and the algorithm converges to the global minimum in a singlestep.Now suppose we wish to minimize the same function, but subject to theconstraint xx ≤ 1. To do so, we introduce the LagrangianL(x, λ) = f(x) + λxx − 1. (4.23)We can now solve the problemminxmaxλ,λ≥0L(x, λ). (4.24)The smallest-norm solution to the unconstrained least-squares problem may befound using the Moore-Penrose pseudoinverse:x=A+b. If this point is feasible,then it is the solution to the constrained problem. Otherwise, we must ﬁnd a94
CHAPTER 4. NUMERICAL COMPUTATIONsolution where the constraint is active. By diﬀerentiating the Lagrangian withrespect to x, we obtain the equationAAx − Ab + 2λx = 0. (4.25)This tells us that the solution will take the formx = (AA + 2λI)−1Ab. (4.26)The magnitude ofλmust be chosen such that the result obeys the constraint. Wecan ﬁnd this value by performing gradient ascent on λ. To do so, observe∂∂λL(x, λ) = xx − 1. (4.27)When the norm ofxexceeds 1, this derivative is positive, so to follow the derivativeuphill and increase the Lagrangian with respect toλ, we increaseλ. Because thecoeﬃcient on thexxpenalty has increased, solving the linear equation forxwill now yield a solution with a smaller norm. The process of solving the linearequation and adjustingλcontinues untilxhas the correct norm and the derivativeon λ is 0.This concludes the mathematical preliminaries that we use to develop machinelearning algorithms. We are now ready to build and analyze some full-ﬂedgedlearning systems.95